"""
LangGraph State Definitions for Research Analyst Agent

This module defines the state structure that is shared across all nodes in the
research analyst agent workflow. The state follows LangGraph best practices by
storing only long-term necessary data, with transformations and formatting
performed in each node.

Design Reference:
    基本設計書.md Section 4.2 - State Design
"""

from typing import TypedDict, Annotated, Callable
from langgraph.graph import add_messages


class AgentState(TypedDict):
    """
    Main state structure for the research analyst agent workflow.

    This state is shared across all nodes in the LangGraph workflow and contains
    all necessary information for executing the research and analysis pipeline.

    Attributes:
        messages: User and agent dialogue history. Uses LangGraph's add_messages
                  reducer to properly append messages without duplication.
        query: Current search query string extracted from user input.
        search_results: Raw search results from web-search-mcp. Each result
                       contains title, URL, description, and full content.
        processed_data: Data processed in container environments. Includes parsed
                       documents, extracted information, and processing logs.
        provisional_answer: Provisional answer generated by LLM before verification.
                           This is a candidate answer that may need refinement.
        final_report: Final verified report in Markdown format. This is the output
                     delivered to the user after all verification loops complete.
        language: User's preferred language. Either 'ja' (Japanese) or 'en' (English).
                 Detected from user input or explicitly specified.
        model_name: Name of the LLM model to use. Default is 'gpt-oss:20b'.
                   Can be changed via configuration or CLI arguments.
        history_path: File system path where session history should be saved.
                     Typically 'session_<timestamp>' format.
        verification_count: Number of verification loops executed. Used to prevent
                           infinite loops and track processing depth.
        errors: List of error messages encountered during workflow execution.
               Helps with debugging and provides feedback to users.

    State Management Notes:
        - State should hold only raw/minimally processed data
        - Formatting and transformations happen in each node
        - List fields use reducers to append rather than replace
        - State enables durable execution and checkpoint recovery
    """

    messages: Annotated[list[dict], add_messages]
    """Dialogue history with message reducer to append new messages"""

    query: str
    """Current search query"""

    search_results: list[dict]
    """Web search results with full content"""

    processed_data: list[dict]
    """Data processed in container environments"""

    provisional_answer: str
    """Provisional answer before verification"""

    final_report: str
    """Final verified report (Markdown)"""

    language: str
    """User language: 'ja' or 'en'"""

    model_name: str
    """LLM model name (default: gpt-oss:20b)"""

    history_path: str
    """History file save path"""

    verification_count: int
    """Number of verification loops executed"""

    errors: list[str]
    """Error messages if any"""


def create_initial_state(
    query: str = "",
    language: str = "ja",
    model_name: str = "gpt-oss:20b",
    history_path: str = ""
) -> AgentState:
    """
    Create an initial state with default values.

    This helper function creates a properly initialized AgentState with default
    values for all fields. It's useful for starting a new workflow execution.

    Args:
        query: Initial user query (default: empty string)
        language: User's preferred language (default: 'ja')
        model_name: LLM model to use (default: 'gpt-oss:20b')
        history_path: Path for history files (default: empty, should be set by system)

    Returns:
        AgentState: Initialized state ready for workflow execution

    Example:
        >>> state = create_initial_state(
        ...     query="LangGraphについて教えて",
        ...     language="ja"
        ... )
        >>> state['query']
        'LangGraphについて教えて'
    """
    return AgentState(
        messages=[],
        query=query,
        search_results=[],
        processed_data=[],
        provisional_answer="",
        final_report="",
        language=language,
        model_name=model_name,
        history_path=history_path,
        verification_count=0,
        errors=[]
    )


def add_error(state: AgentState, error_message: str) -> dict:
    """
    Helper function to add an error message to state.

    Args:
        state: Current agent state
        error_message: Error message to add

    Returns:
        dict: State update with new error appended

    Example:
        >>> update = add_error(state, "Search failed: timeout")
        >>> # In a node: return add_error(state, "Error description")
    """
    return {"errors": state.get("errors", []) + [error_message]}


def increment_verification_count(state: AgentState) -> dict:
    """
    Helper function to increment verification count.

    Args:
        state: Current agent state

    Returns:
        dict: State update with incremented verification_count

    Example:
        >>> update = increment_verification_count(state)
        >>> # In verification node: return increment_verification_count(state)
    """
    return {"verification_count": state.get("verification_count", 0) + 1}


# Type hints for node functions
NodeFunction = Callable[[AgentState], dict]
"""Type alias for LangGraph node functions that take state and return updates"""
